{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnI3Oh6U8fof"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load datasets\n",
        "df = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['summary'])\n",
        "X_test = vectorizer.transform(test_data['summary'])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['severity'])\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "temp_df, X_test_df, temp_y, test_y = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "train_df, val_df, train_y, val_y = train_test_split(temp_df, temp_y, test_size=0.2, random_state=42, stratify=temp_y)\n",
        "\n",
        "# Define the AdaBoost classifier with a DecisionTree base estimator\n",
        "ada_boost = AdaBoostClassifier(estimator=DecisionTreeClassifier())\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'estimator__max_depth': [1, 2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello1\")\n",
        "# Perform GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=ada_boost, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(train_df, train_y)\n",
        "print(\"hello2\")\n",
        "# Get the best estimator\n",
        "best_ada_boost = grid_search.best_estimator_\n",
        "print(\"hello3\")\n",
        "# Evaluate on the validation set\n",
        "val_pred = best_ada_boost.predict(val_df)\n",
        "print('Validation Classification Report:')\n",
        "print(classification_report(val_y, val_pred))\n",
        "\n",
        "# Predict the severities for the test data\n",
        "test_pred = best_ada_boost.predict(X_test)\n",
        "\n",
        "# Correctly map predicted labels back using the label encoder\n",
        "predicted_labels_mapped = label_encoder.inverse_transform(test_pred)\n",
        "\n",
        "# Save the predictions\n",
        "pred_df = pd.DataFrame({\n",
        "    'bug_id': test_data['bug_id'],\n",
        "    'severity': predicted_labels_mapped\n",
        "})\n",
        "pred_df.to_csv(\"adaboost_predicted_bugs2.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to 'adaboost_predicted_bugs.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJZNGU7X8qQs",
        "outputId": "980d0f23-e0b3-4d1e-ed39-31e57f4bf18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello1\n",
            "hello2\n",
            "hello3\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        98\n",
            "           1       0.78      0.58      0.67      2612\n",
            "           2       0.00      0.00      0.00       620\n",
            "           3       0.00      0.00      0.00       847\n",
            "           4       0.00      0.00      0.00       434\n",
            "           5       0.84      0.98      0.91     17620\n",
            "           6       0.00      0.00      0.00       169\n",
            "\n",
            "    accuracy                           0.84     22400\n",
            "   macro avg       0.23      0.22      0.23     22400\n",
            "weighted avg       0.76      0.84      0.79     22400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'adaboost_predicted_bugs.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import regex\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def filter_text(text, stop_words):\n",
        "    word_tokens = WordPunctTokenizer().tokenize(text.lower())\n",
        "    filtered_text = [regex.sub('[^a-z ]+', '', w) for w in word_tokens]\n",
        "    filtered_text = [regex.sub('[ ][ ]+', '', w) for w in filtered_text]\n",
        "    filtered_text = [regex.sub('[0-9]', '', w) for w in filtered_text]\n",
        "    filtered_text = [wordnet_lemmatizer.lemmatize(w, 'v') for w in filtered_text if not w in stop_words and len(w) > 2 and len(w) < 50]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "df = pd.read_csv(\"bugs-train.csv\")\n",
        "df = df[df['severity'] != \"trivial\"] #not in the given classes\n",
        "df[\"filtered_text\"] = df[\"summary\"].apply(lambda x : filter_text(x, stop))\n",
        "df.head()\n",
        "\n",
        "df['classification'] = df['severity'].replace(['enhancement', 'minor', 'normal', 'major', 'blocker','critical'],[1,2,3,4,5,6])\n",
        "df['classification'] = df['classification'].dropna()\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df = df.dropna()\n",
        "df['classification'].astype(int)\n",
        "\n",
        "temp_df, test_df = train_test_split(df, test_size=0.3, random_state = 42, stratify = df['classification'])\n",
        "train_df, val_df = train_test_split(temp_df, test_size=0.2, random_state = 42, stratify = temp_df['classification'])\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words = 'english',  min_df = 2, max_features = 17673, use_idf = True)\n",
        "x_train = tfidf.fit_transform(train_df['filtered_text'])\n",
        "x_val = tfidf.transform(val_df['filtered_text'])\n",
        "y_train = train_df['classification']\n",
        "y_val = val_df['classification']\n",
        "\n",
        "x_test = tfidf.transform(test_df['filtered_text'])\n",
        "y_test = test_df['classification']\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and fit the AdaBoost model\n",
        "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "adaboost_model.fit(x_train, y_train)\n",
        "\n",
        "y_val_pred = adaboost_model.predict(x_val)\n",
        "print(\"Validation Accuracy: \", accuracy_score(y_val, y_val_pred))\n",
        "print(\"Validation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=adaboost_model.classes_)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "y_test_pred = adaboost_model.predict(x_test)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=adaboost_model.classes_)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "pred_df = pd.read_csv(\"bugs-test.csv\")\n",
        "pred_df['filtered_text'] = pred_df[\"summary\"].apply(lambda x : filter_text(x, stop))\n",
        "\n",
        "tfidf1 = TfidfVectorizer(stop_words = 'english',  min_df = 2, max_features = 17673, use_idf = True)\n",
        "x_test = tfidf1.fit_transform(pred_df['filtered_text'])\n",
        "\n",
        "predictions = adaboost_model.predict(x_test)\n",
        "\n",
        "severity_mapping = {'enhancement': 1, 'minor': 2, 'normal': 3, 'major': 4, 'blocker': 5, 'critical': 6}\n",
        "inverse_severity_mapping = {v: k for k, v in severity_mapping.items()}\n",
        "predictions_labels = [inverse_severity_mapping[pred] for pred in predictions]\n",
        "\n",
        "pred_df['prediction'] = predictions\n",
        "pred_df = pd.DataFrame({\n",
        "    'bug_id': pred_df['bug_id'],\n",
        "    'prediction': predictions_labels\n",
        "})\n",
        "pred_df.to_csv(\"predicted_bugs.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predicted_bugs.csv'\")\n"
      ],
      "metadata": {
        "id": "k2BqYIC08qV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xUAYd6n8qXl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}